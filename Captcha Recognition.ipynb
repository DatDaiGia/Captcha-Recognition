{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# !pip install imutils\n",
    "import imutils\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, BaseLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"output/\"\n",
    "TEST_DIR = \"datasets/yzm/\"\n",
    "HEIGTH = 28\n",
    "WIDTH = 28\n",
    "CHANNEL = 1\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n",
    "               \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\",\n",
    "               \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \n",
    "               \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGerenation:\n",
    "    def __init__(self, data_dir, height, width, channel, class_names):\n",
    "        self.data_dir = data_dir\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channel = channel\n",
    "        self.class_names = class_names\n",
    "        self.current_train = 0\n",
    "        self.current_test = 0\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        \n",
    "    def image_preprocess(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        if w > h: \n",
    "            image = imutils.resize(image, width=self.width)\n",
    "        else:\n",
    "            image = imutils.resize(image, height=self.height)\n",
    "        \n",
    "        h_, w_ = image.shape[:2]\n",
    "        pad_w = int((self.width - w_)/2)\n",
    "        pad_h = int((self.height - h_)/2)\n",
    "        \n",
    "#         if pad_w > 0:\n",
    "#             image = cv2.copyMakeBorder(image, 0, 0, pad_w, pad_w, cv2.BORDER_REPLICATE)\n",
    "#         else:\n",
    "#         print(pad_h, pad_h, pad_w, pad_w)\n",
    "        image = cv2.copyMakeBorder(image, pad_h, pad_h, pad_w, pad_w, cv2.BORDER_REPLICATE)\n",
    "        image = cv2.resize(image, (self.width, self.height))\n",
    "        return image\n",
    "    \n",
    "    def load_image(self, image_path):\n",
    "        image = cv2.imread(image_path, 0)\n",
    "        image = self.image_preprocess(image)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        return image\n",
    "    \n",
    "    def load_image_paths(self):\n",
    "        image_paths = []\n",
    "        \n",
    "        for cl_name in os.listdir(self.data_dir):\n",
    "            if cl_name == \".DS_Store\": continue\n",
    "            cl_name_path = os.path.join(self.data_dir, cl_name)\n",
    "            \n",
    "            for img in os.listdir(cl_name_path):\n",
    "                if img == \".DS_Store\": continue\n",
    "                img_path = os.path.join(cl_name_path, img)\n",
    "                image_paths.append(img_path)\n",
    "                \n",
    "        return image_paths\n",
    "    \n",
    "    def load_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        current_y = 0\n",
    "        image_paths = self.load_image_paths()\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            image = self.load_image(img_path)\n",
    "            label = img_path.split(\"/\")[-2]\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "            \n",
    "        try:\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def split_train_test(self):\n",
    "        X, y = self.load_data()\n",
    "        X, y = shuffle(X, y, random_state=42)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "        \n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "    \n",
    "    def next_train(self, X, y):\n",
    "        if self.current_train + 32 > X.shape[0]:\n",
    "            X, y = shuffle(X, y, random_state=42)\n",
    "            self.current_train = 0\n",
    "        \n",
    "        batch_X = X[self.current_train:self.current_train+32]\n",
    "        batch_y = y[self.current_train:self.current_train+32]\n",
    "        self.current_train += 32\n",
    "        \n",
    "        return batch_X, batch_y\n",
    "    \n",
    "    def next_test(self, X, y):\n",
    "        if self.current_test + 32 > X.shape[0]:\n",
    "            X, y = shuffle(X, y, random_state=42)\n",
    "            self.current_test = 0\n",
    "        \n",
    "        batch_X = X[self.current_test:self.current_test+32]\n",
    "        batch_y = y[self.current_test:self.current_test+32]\n",
    "        self.current_test += 32\n",
    "        \n",
    "        return batch_X, batch_y\n",
    "    \n",
    "    def generate(self, X, y, s=\"train\"):\n",
    "        while True:\n",
    "            if s == \"train\":\n",
    "                batch_X, batch_y = self.next_train(X, y)\n",
    "            else:\n",
    "                batch_X, batch_y = self.next_test(X, y)\n",
    "            \n",
    "#             print(s, batch_X.shape, batch_y.shape)\n",
    "                \n",
    "            yield (batch_X, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gener = DataGerenation(DATA_DIR, 28, 28, 1, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_gener.split_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train/255, X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6339, 28, 28, 1), (2114, 28, 28, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelBinarizer().fit(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6339, 36)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_test[4].argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias(shape, dtype=None):\n",
    "    return np.random.normal(loc=0.5, scale=1e-2, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCHeadNet:\n",
    "    @staticmethod\n",
    "    def build(base_model, classes, D):\n",
    "        head_model = base_model.output\n",
    "        head_model = Flatten(name=\"Flatten\")(head_model)\n",
    "        head_model = Dense(D, activation=\"relu\")(head_model)\n",
    "        head_model = Dropout(0.5)(head_model)\n",
    "        \n",
    "        head_model = Dense(classes, activation=\"softmax\")(head_model)\n",
    "        return head_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVGG:\n",
    "    @staticmethod\n",
    "    def build(height, width, channel, n_classes):\n",
    "        model = Sequential()\n",
    "        input_shape = (width, height, channel)\n",
    "        \n",
    "        if K.image_data_format == \"channels_first\":\n",
    "            input_shape = (channel, width, height)\n",
    "            \n",
    "        # First conv block\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\", \n",
    "                         input_shape=input_shape, \n",
    "                         kernel_regularizer=l2(1e-4),\n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\", \n",
    "                         kernel_regularizer=l2(1e-4),\n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        #Second conv block\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\", \n",
    "                         kernel_regularizer=l2(1e-4), \n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\", \n",
    "                         kernel_regularizer=l2(1e-4), \n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        #Third conv block\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\", \n",
    "                         kernel_regularizer=l2(1e-4), \n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\", \n",
    "                         kernel_regularizer=l2(1e-4), \n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        #Fourth conv block\n",
    "        model.add(Conv2D(512, (3, 3), padding=\"same\", \n",
    "                         kernel_regularizer=l2(1e-4), \n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(512, (3, 3), padding=\"same\", \n",
    "                         kernel_regularizer=l2(1e-4), \n",
    "                         bias_initializer=initialize_bias))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        # Flatten\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, kernel_regularizer=l2(1e-3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(n_classes, kernel_regularizer=l2(1e-3)))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 36)                147492    \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 36)                0         \n",
      "=================================================================\n",
      "Total params: 6,940,644\n",
      "Trainable params: 6,936,804\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MiniVGG.build(28, 28, 1, len(class_names))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_scheduler(epoch):\n",
    "    initial_lr = 0.01\n",
    "    F = 0.5\n",
    "    D = 10\n",
    "    new_lr = initial_lr * (F**np.floor((1+epoch)/D))\n",
    "    \n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"./weights\"\n",
    "\n",
    "if not os.path.exists(weight_path):\n",
    "    os.mkdir(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weigth_path = weight_path + \"/best_weight.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(best_weigth_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [LearningRateScheduler(learning_rate_scheduler), checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit_generator(data_gener.generate(X_train, y_train), \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    validation_steps=len(X_test)//BATCH_SIZE,\n",
    "                    steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
    "                    epochs=200, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(classification_report(predictions.argmax(axis=1), y_test.argmax(axis=1), target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 200), H.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.plot(np.arange(0, 200), H.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(np.arange(0, 200), H.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.plot(np.arange(0, 200), H.history[\"accuracy\"], label=\"Train acc\")\n",
    "plt.title(\"Monitor training model\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Train/Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_weight.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint, choice\n",
    "\n",
    "image_paths = os.listdir(TEST_DIR)\n",
    "# image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prediction():\n",
    "    idx = randint(0, len(image_paths))\n",
    "    img_path = os.path.join(TEST_DIR, image_paths[idx])\n",
    "    image = cv2.imread(img_path)\n",
    "    plt.imshow(image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0]\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:4]\n",
    "    \n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "        if w > 40:\n",
    "            roi = gray[y-5:y+5+h, x-5:x + int(w/2)]\n",
    "            roi_2 = gray[y-5:y+5+h, x + int(w/2):x+5+int(w/2)]\n",
    "#             plt.imshow(roi)\n",
    "            roi = data_gener.image_preprocess(roi)\n",
    "            roi = np.expand_dims(roi, axis=-1)\n",
    "            roi_2 = data_gener.image_preprocess(roi_2)\n",
    "            roi_2 = np.expand_dims(roi_2, axis=-1)\n",
    "            rois = np.array([roi, roi_2])\n",
    "        else:\n",
    "            roi = gray[y-5:y+5+h, x-5:x+5+w]\n",
    "#             plt.imshow(roi)\n",
    "            roi = data_gener.image_preprocess(roi)\n",
    "            roi = np.expand_dims(roi, axis=-1)\n",
    "            rois = np.array([roi])\n",
    "\n",
    "        for roi in rois:    \n",
    "            prediction = model.predict(roi.reshape(1, 28, 28, 1))\n",
    "#             print(prediction)\n",
    "            print(le.classes_[prediction.argmax(axis=1)[0]])\n",
    "                \n",
    "#     plt.imshow(thresh, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "H\n",
      "H\n",
      "H\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
